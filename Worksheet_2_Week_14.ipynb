{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "Worksheet 2 Week 14.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamesExeter/AI_WorkSheet_2/blob/main/Worksheet_2_Week_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZVCXY9TWxaw"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This worksheet covers the three supervised learning algorithms we looked at in week 14: k-nearest neighbours, linear regression, and the naive Bayes classifier. Similar to last week, you will do some work implementing your own versions of these algorithms, to ensure that you understand the details of them. You will also compare them with the implementations in scikit-learn to test your implementations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ9-BHP1Wxa7"
      },
      "source": [
        "# Preliminaries\n",
        "Import key packages: NumPy, matplotlib, and any others that you prefer to work with. In general, when writing code, you will put all your import statements at the top. However, for these worksheets we will import as we go along."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAY47-ATWxa8"
      },
      "source": [
        "#TODO: import NumPy and matplotlib here\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khmnw9RDWxa9"
      },
      "source": [
        "# Question 1: k-nearest neighbours classification\n",
        "In this question we will use the k-nearest neighbours algorithm to make predictions on the breast cancer Wisconsin dataset. This is a classification problem where the aim is to classify instances as either being malignant or benign based on the following 10 features:\n",
        "1. radius (mean of distances from center to points on the perimeter)\n",
        "2. texture (standard deviation of gray-scale values)\n",
        "3. perimeter\n",
        "4. area\n",
        "5. smoothness (local variation in radius lengths)\n",
        "6. compactness (perimeter squared/ area −1)\n",
        "7. concavity (severity of concave portions of the contour)\n",
        "8. concave points (number of concave portions of the contour)\n",
        "9. symmetry\n",
        "10. fractal dimension (‘coastline approximation’ −1)\n",
        "\n",
        "In this question you will (a) download the dataset from sklearn and store the data and targets in suitable variables, (b) separate your data into a training and test split, (c) write your own function to implement k-nearest neighbours, (d) check your implementation with that of sklearn. Wethen go on to (e) select the most appropriate value of $k$ using cross-validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmWrtb_7Wxa9"
      },
      "source": [
        "## Part (a)\n",
        "Import the package `datasets` from `sklearn` and then load the breast cancer dataset (function is `load_breast_cancer()`). Save the data into a variable `X` and the targets into a variable `Y`. \n",
        "Take a look at the data in `X`. How many datapoints are there? How many features does each datapoint have? (Hint: use `np.shape`).\n",
        "Take a look at the targets. Is this suitable for a classification algorithm or a regression algorithm?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X367Cti1Wxa-",
        "outputId": "8d1f1e88-2ab5-4197-ef41-87e9eda82d62"
      },
      "source": [
        "# Import suitable packages, load the dataset, and save data and targets into variables X and Y\n",
        "# import packages\n",
        "##TODO##\n",
        "from sklearn import datasets\n",
        "\n",
        "# load dataset and save data and targets into X and Y\n",
        "##TODO##\n",
        "data = datasets.load_breast_cancer() # load the dataset\n",
        "X = data.data # extract the features\n",
        "Y = data.target # extract the labels\n",
        "\n",
        "np.shape(X) # 30 features and 569 observations\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mCjaN0nbpw4",
        "outputId": "1ebb7b41-5950-4fe8-9540-bce69826b7a6"
      },
      "source": [
        "Y[20:30] # suitable for classification as only two classes, not regression"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW1bA5_NWxa-"
      },
      "source": [
        "## Part (b)\n",
        "\n",
        "Use the function `train_test_split` from `sklearn.model_selection` to split your data into a training set and a held-out test set. Use a test set that is 0.2 of the original dataset. Set the parameter `random_state` to 10 to help with replication."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68adSw5CWxa_"
      },
      "source": [
        "# Import the package train_test_split from sklearn.model_selection.\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split the dataset into Xtr, Xtest, Ytr, Ytest. Xtest and Ytest will form your held-out\n",
        "# test set. You will later split Xtr and Ytr into training and validation sets.\n",
        "Xtr, Xtest, Ytr, Ytest = train_test_split(X, Y, test_size = 0.2, random_state = 41)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTTh2ZNoWxa_"
      },
      "source": [
        "## Part (c) \n",
        "Recall from the lecture that the k-nearest neighbours algorithm runs as follows:\n",
        "\n",
        "Training step: Simply store the dataset\n",
        "\n",
        "Prediction step: Given a datapoint $\\vec{x}$:\n",
        " - **Find** the k datapoints $(\\vec{x}_i, y_i)$ where the distance from $\\vec{x}$ to $\\vec{x}_i$ is smallest\n",
        " - **Return** the majority class from the $y_i$\n",
        "   \n",
        " \n",
        "What, if anything, do you need to do for the training step?\n",
        "\n",
        "Write function(s) to implement the k-nearest neighbours prediction step. You may wish to break the procedure down into two functions `predict_datapoint` that makes a prediction for one datapoint and `predict_data` that loops over the whole dataset.\n",
        "\n",
        "To select the majority class from the nearest neighbours, you can use the function `scipy.stats.mode()`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItncHQSoWxbA",
        "outputId": "807e46e1-5713-499f-aff2-15b32f271a3b"
      },
      "source": [
        "from scipy.stats import mode\n",
        "import math\n",
        "# Write function(s) to implement the prediction step in k-nearest neighbours. \n",
        "# You can use the suggested structure below if desired.\n",
        "\n",
        "def get_distance(data1, data2):\n",
        "    points = zip(data1, data2)\n",
        "    diffs_squared_distance = [pow(a - b, 2) for (a, b) in points]\n",
        "    return math.sqrt(sum(diffs_squared_distance))\n",
        "\n",
        "# predict_datapoint takes 4 arguments. pt (type: numpy array) is the datapoint we are making a prediction about, \n",
        "# Xtrain and Ytrain (numpy arrays) are training data and targets, k (int) is the number of neighbours.\n",
        "# Returns an integer which is the predicted class for pt\n",
        "def predict_datapoint(pt, Xtrain, Ytrain, k):\n",
        "    # For each datapoint in Xtrain, calculate the distance to pt and store\n",
        "    ##TODO##\n",
        "    dists = []\n",
        "    for next_pt in Xtrain:\n",
        "      dist = get_distance(pt, next_pt)\n",
        "      dists.append(dist)\n",
        "        \n",
        "    # Sort the list of distances (hint: use np.argsort)\n",
        "    ##TODO##\n",
        "    dists_idxs = np.argsort(dists)\n",
        "    \n",
        "    # obtain the classes (in Ytrain) of the datapoints with the smallest distance to pt\n",
        "    ##TODO##\n",
        "    classes_near = Ytrain[dists_idxs]\n",
        "    classes_near = classes_near[:k]\n",
        "    \n",
        "    # return the mode of the classes\n",
        "    ##TODO##\n",
        "    return mode(classes_near)[0][0]\n",
        "\n",
        "# predict_data takes 4 arguments: the test data Xtst (numpy array), the training data Xtrain (numpy array),\n",
        "# the training targets Ytrain (numpy array), and the number of neighbours k (int, default = 3). \n",
        "# Returns: predictions (array of int) for each point in Xtst\n",
        "def predict_data(Xtst, Xtrain, Ytrain, k=3):\n",
        "    #Loop over the datapoints in Xtst and store the prediction for that datapoint\n",
        "    ##TODO##\n",
        "    predicts = []\n",
        "    for pt in Xtst:\n",
        "      predicts.append(predict_datapoint(pt, Xtrain, Ytrain, k))\n",
        "\n",
        "    # Return the predictions\n",
        "    ##TODO##\n",
        "    return predicts\n",
        "\n",
        "# Predict values for the TRAINING data (we will not look at the test set yet)\n",
        "##TODO##\n",
        "predictions = predict_data(Xtr, Xtr, Ytr)\n",
        "print(predictions)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXnmxjYCWxbA"
      },
      "source": [
        "## Part (d)\n",
        "Now we can compare your implementation with the sklearn implementation (you should get the same results). Firstly import the classfifier `KNeighborsClassifier` from `sklearn.neighbors`. Instantiate the classifier with the same number of neighbours that you used previously. Fit the model and make a prediction on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hbS2DCCWxbB",
        "outputId": "2156a3a5-8ee6-4b82-af2a-c5012d8834fe"
      },
      "source": [
        "# Import KNeighborClassifier\n",
        "##TODO##\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Instantiate the classifier with 3 neighbors\n",
        "##TODO##\n",
        "classifier = KNeighborsClassifier(n_neighbors = 3)\n",
        "\n",
        "#Fit the classifier on the training data\n",
        "##TODO##\n",
        "classifier.fit(Xtr, Ytr)\n",
        "\n",
        "#Make a prediction on the training data\n",
        "##TODO##\n",
        "predictions_built_in = classifier.predict(Xtr)\n",
        "print(predictions_built_in)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 0\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1\n",
            " 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1\n",
            " 1 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
            " 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 0 1\n",
            " 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0\n",
            " 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1 0 1\n",
            " 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1\n",
            " 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1\n",
            " 1 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0\n",
            " 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1\n",
            " 0 1 0 1 0 0 1 1 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Rq7aYBMWxbB"
      },
      "source": [
        "Check whether your predictions are the same as the predictions from `KNeighborsClassifier`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCkMkJq4WxbC",
        "outputId": "2432d381-bb5b-4ca1-9b1a-8c43e71dd750"
      },
      "source": [
        "##TODO##\r\n",
        "predictions == predictions_built_in"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THt9xB-bWxbC"
      },
      "source": [
        "Use the built in metrics in sklearn to calculate the accuracy of your classifier on the TRAINING set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T3Je-GeWxbD",
        "outputId": "f90515b5-c0dc-4640-9771-8525dc594522"
      },
      "source": [
        "##TODO## \r\n",
        "from sklearn import metrics\r\n",
        "\r\n",
        "print(\"Accuracy:\", metrics.accuracy_score(Ytr, predictions))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9472527472527472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUOjBwMeWxbD"
      },
      "source": [
        "## Part(e) Using cross-validation for model selection\n",
        "k-nearest neighbours has the parameter $k$, and we need to decide which is the best value of $k$ to use. Last week we talked about using cross-validation for model selection.\n",
        "\n",
        "We will use cross-validation on our training set to select the best value of $k$, in a range from 1 to 30.\n",
        "\n",
        "NB: use sklearn's version of k-NN rather than yours, since unless you have optimised yours it is probably too slow.\n",
        "\n",
        "Since we are using cross-validation for model selection we will cross-validate on the training set only.\n",
        "\n",
        "Procedure:\n",
        "        \n",
        " 1. Import `KFold` from `sklearn.model_selection`  \n",
        " 1. Instantiate `KFold` with 5 splits. Set the parameter `random_state` to help you reproduce your results if needed.\n",
        " 1. Set a variable `max_k` to 30  \n",
        " 1. Inititalise two variables to store the training accuracies and validation accuracies (these need to store max_k\\*5 accuracies)  \n",
        " 1. Loop over the values of k:  \n",
        "    1. Instantiate a k-nn classifier (Use the sklearn classifier) with the current value of k  \n",
        "    1. Loop over the cross-validation splits:  \n",
        "       1. fit the model on the current split of data  \n",
        "       1. make predictions  \n",
        "       1. calculate training and validation accuracy and store  \n",
        " 6. Calculate the mean training and validation accuracies across splits for each $k$\n",
        "\n",
        "Plot the mean training and validation accuracies. Which value of $k$ will you use? Why?\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCHd_XhCWxbE",
        "outputId": "ab1d2df0-a8de-470b-dd7f-21f74468a99f"
      },
      "source": [
        "# Use cross-validation to select the value of k\n",
        "# You can use the structure below if desired\n",
        "\n",
        "# Import KFold from sklearn.model_selection\n",
        "##TODO##\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Instantiate KFold with 5 splits. \n",
        "# Set the parameter random_state to help you reproduce your results if needed.\n",
        "##TODO##\n",
        "kf = KFold(n_splits = 5, random_state = 4)\n",
        "\n",
        "# Set a variable max_k to 30 \n",
        "##TODO##\n",
        "max_k = 30\n",
        "\n",
        "# Inititalise two variables to store the \n",
        "# training accuracies and validation accuracies \n",
        "# (these need to store max_k*5 accuracies) \n",
        "##TODO##\n",
        "train_accs = []\n",
        "valid_accs = []\n",
        "\n",
        "# Loop over the values of k: \n",
        "for k in range(max_k):\n",
        "    \n",
        "    # Instantiate a k-nn classifier (Use the sklearn classifier)\n",
        "    # with the current value of k \n",
        "    ##TODO##\n",
        "    classifier = KNeighborsClassifier(n_neighbors = k+1)\n",
        "    k_train_accs = []\n",
        "    k_valid_accs = []\n",
        "\n",
        "    # Loop over the cross-validation splits: \n",
        "    ##TODO##\n",
        "    for train_idx, test_idx in kf.split(Xtr):\n",
        "        Xtrain, Xval = Xtr[train_idx], Xtr[test_idx]\n",
        "        Ytrain, Yval = Ytr[train_idx], Ytr[test_idx]\n",
        "        # fit the model on the current split of data \n",
        "        ##TODO##\n",
        "        classifier.fit(Xtrain, Ytrain)\n",
        "        \n",
        "        # make predictions \n",
        "        ##TODO##\n",
        "        train_y_pred = classifier.predict(Xtrain)\n",
        "        val_y_pred = classifier.predict(Xval)\n",
        "        \n",
        "        # calculate training and validation accuracy and store \n",
        "        ##TODO##\n",
        "        k_train_accs.append(metrics.accuracy_score(Ytrain, train_y_pred))\n",
        "        k_valid_accs.append(metrics.accuracy_score(Yval, val_y_pred))\n",
        "    \n",
        "    train_accs.append(np.mean(k_train_accs))\n",
        "    valid_accs.append(np.mean(k_valid_accs))\n",
        "        \n",
        "# Calculate the mean training and validation accuracies across splits for each 𝑘\n",
        "##TODO##\n",
        "mean_train_acc = np.mean(train_accs)\n",
        "mean_val_acc = np.mean(valid_accs)\n",
        "\n",
        "print(\"Training mean\", mean_train_acc)\n",
        "print(\"Validation mean\", mean_val_acc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training mean 0.9341575091575092\n",
            "Validation mean 0.9241758241758242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "1oQaoNxpWxbF",
        "outputId": "396dad82-b403-41bc-fa84-d1c37abd8df1"
      },
      "source": [
        "# Plot the mean training and validation accuracies against each value of k. Which value of 𝑘 will you use? Why?\n",
        "##TODO##\n",
        "k_vals = [k+1 for k in range(30)]\n",
        "\n",
        "plt.plot(k_vals, train_accs, label = \"Training accuracy\")\n",
        "plt.plot(k_vals, valid_accs, label = \"Validation accuracy\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "\n",
        "print(valid_accs.index(np.max(valid_accs)))\n",
        "\n",
        "# The maximum accuracy obtained on the validation data was given by k = 6 so this is the value that should be used.\n",
        "# We don't use the accuracy for the training set as that would mean overfitting on the training data for all future data predicted on"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9FS_p_dWxbG"
      },
      "source": [
        "# The naive Bayes classifier\n",
        "\n",
        "Recall from the lecture notes that the naive Bayes classifier works as follows. We are trying to approximate an unknown function $$f:\\Omega \\rightarrow \\mathcal{O}$$\n",
        "where $\\Omega$ is our feature space and our output space $\\mathcal{O} = \\{c_1, c_2, ... c_K\\}$ is a finite set of classes.\n",
        "\n",
        "The naive Bayes classifier does this by building a model that assigns the class label $\\hat{y} = c_k$ as follows:\n",
        "$$\n",
        "\\hat{y} = \\text{argmax}_k p(c_k)\\prod_i p(x_i| c_k)\n",
        "$$\n",
        "i.e., the $k$ that maximises this quantity.\n",
        "\n",
        "In practice, multiplying all the $p(x_i| c_k)$ together is going to give some very small values. Therefore, we can take the log to make it easier to compute:\n",
        "\\begin{align}\n",
        "\\hat{y} &= \\text{argmax}_k p(c_k)\\prod_i p(x_i| c_k)= \\text{argmax}_k log(p(c_k)\\prod_i p(x_i| c_k))\\\\\n",
        "&=\\text{argmax}_k log(p(c_k)) + \\sum_i log(p(x_i|c_k))\n",
        "\\end{align}\n",
        "\n",
        "If we choose that $p(x_i|c_k)$ is given by a normal distribution with mean $\\mu_k$ and variance $\\sigma_k^2$, then we obtain the following expression:\n",
        "\n",
        "\\begin{align}\n",
        "\\hat{y} &=\\text{argmax}_k \\log(p(c_k)) + \\sum_i \\log(p(x_i|c_k))\\\\\n",
        "&= \\text{argmax}_k \\log(p(c_k)) + \\sum_i \\log\\left(\\frac{1}{\\sigma_k\\sqrt{2\\pi}} exp\\left(\\frac{-(x-\\mu_k)^2}{2\\sigma_k}\\right)\\right)\\\\\n",
        "&= \\text{argmax}_k \\log(p(c_k)) - \\sum_i \\log\\left(\\sigma_k\\sqrt{2\\pi}\\right) - \\sum_i\\left(\\frac{(x-\\mu_k)^2}{2\\sigma_k}\\right) \\quad \\text{ log-likelihood}\n",
        "\\end{align}\n",
        "\n",
        "Expressing the values in terms of these sums means that they do not get so small, and it is less likely that there will be errors at the machine precision level.\n",
        "\n",
        "\n",
        "How do we implement this in practice? We assume that each probability $p(x_i| c_k)$ is given by some distribution, and then given a datapoint $\\vec{x}$, we plug the value into the equation for the distribution.\n",
        "\n",
        "In this question you will (a) implement your own version of the Gaussian naive Bayes classifier, (b) check your classifier against the implementation in sci-kit learn, (c) compare the accuracy of the naive Bayes classifier with the accuracy of the k-nearest neighbours classifier, and (d) run cross-validation to verify whether the kNN classfier or the Gaussian naive Bayes classifier performs better on this dataset.\n",
        "\n",
        "## Part (a) Implementing Gaussian naive Bayes\n",
        "For this question we will make the assumption that each feature is described by a normal (also called Gaussian) distribution. The procedure is as follows:\n",
        "1. Divide the training data by class\n",
        "2. Calculate mean and standard deviation per class and per feature\n",
        "4. For each datapoint in the validation set, calculate the log-likelihood for each class and for each feature (Hint: use the function `scipy.stats.norm.logpdf`)\n",
        "5. Combine these values together with the probability of the class according to the log-likelihood equation above\n",
        "6. Choose the class with the highest value\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecaoGtJjWxbH"
      },
      "source": [
        "##TODO##\n",
        "# Write your own implementation of naive Bayes applied to the breast cancer dataset.\n",
        "\n",
        "# If you wish you can follow the structure below\n",
        "from scipy.stats import norm\n",
        "from math import exp\n",
        "from math import pi\n",
        "\n",
        "# Split the training data Xtr into training and validation sets with an 80:20 split. \n",
        "# Set the random state to help with reproducibility\n",
        "##TODO##\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(Xtr, Ytr, test_size = 0.2, random_state = 41)\n",
        "\n",
        "#Separate the training set into classes, so you have one set of data for each class\n",
        "##TODO##\n",
        "def separate_by_class(data, labels):\n",
        "  separated = dict()\n",
        "  for i in range(len(data)):\n",
        "    vector = data[i]\n",
        "    class_val = labels[i]\n",
        "    if (class_val not in separated):\n",
        "      separated[class_val] = list()\n",
        "\n",
        "    separated[class_val].append(vector)\n",
        "\n",
        "  return separated\n",
        "\n",
        "\"\"\"\n",
        "for label in separated:\n",
        "\tprint(label)\n",
        "\tfor row in separated[label]:\n",
        "\t\tprint(row)\n",
        "\"\"\"\n",
        "\n",
        "# Calculate the means and standard deviations for each class, for each feature. \n",
        "# There are 30 features in the dataset, so you should have a 30-dimensional \n",
        "# array of means for each class and a 30-dimensional array of standard deviations\n",
        "# for each class. Remember that you can take the average across rows or columns of \n",
        "# a matrix by specifying axis = 1 or axis = 0\n",
        "##TODO##\n",
        "\n",
        "def calc_mean(data):\n",
        "  return sum(data) / float(len(data))\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "def calc_sd(data):\n",
        "  avg = calc_mean(data)\n",
        "  variance = sum([(x-avg)**2 for x in data]) /float(len(data)-1)\n",
        "  return sqrt(variance)\n",
        "\n",
        "def summarize(data):\n",
        "  summaries = [(calc_mean(col), calc_sd(col)) for col in zip(*data)]\n",
        "  return summaries\n",
        "\n",
        "def summarize_by_class(sep):\n",
        "  summaries = dict()\n",
        "  for class_val, rows in sep.items():\n",
        "    summaries[class_val] = summarize(rows)\n",
        "  \n",
        "  return summaries\n",
        "\n",
        "\"\"\"\n",
        "for label in summary:\n",
        "\tprint(label)\n",
        "\tfor row in summary[label]:\n",
        "\t\tprint(row)\n",
        "\"\"\"\n",
        "\n",
        "# Calculate the log-likelihood of each class for each datapoint in the validation set\n",
        "# Hint: you can use the function scipy.stats.norm.logpdf to help with this\n",
        "##TODO##\n",
        "def calculate_log_likelihood(x, mean, sd):\n",
        "  expo = exp(-((x-mean)**2 / (2 * sd ** 2)))\n",
        "  return (1 / (sqrt(2 * pi) * sd)) * expo\n",
        "\n",
        "# Calculate the prior probability p(c_i) for each class\n",
        "##TODO##\n",
        "def calculate_class_probs(summaries, row):\n",
        "  probs = {}\n",
        "  for class_val, class_summaries in summaries.items():\n",
        "    probs[class_val] = 1\n",
        "    for i in range(len(class_summaries)):\n",
        "      mean, sd = class_summaries[i]\n",
        "      probs[class_val] *= calculate_log_likelihood(row[i], mean, sd)\n",
        "  \n",
        "  return probs\n",
        "\n",
        "# Your predicted class is 0 if class 0 has the highest log-likelihood, and 1 if class 1 \n",
        "# has the highest log-likelihood\n",
        "##TODO##\n",
        "def predict_nb(summaries, row):\n",
        "  probs = calculate_class_probs(summaries, row)\n",
        "  best_label, best_prob = None, -1\n",
        "  for class_val, prob in probs.items():\n",
        "    if best_label is None or prob > best_prob:\n",
        "      best_prob = prob\n",
        "      best_label = class_val\n",
        "  \n",
        "  return(best_label)\n",
        "\n",
        "def naive_bayes(Xtrain, Ytrain, Xval, Yval):\n",
        "  separated = separate_by_class(Xtrain, Ytrain)\n",
        "  summary = summarize_by_class(separated)\n",
        "  predictions = list()\n",
        "  for row in Xval:\n",
        "    y_val_pred = predict_nb(summary, row)\n",
        "    predictions.append(y_val_pred)\n",
        "  \n",
        "  return predictions\n",
        "\n",
        "implemented_predicts = naive_bayes(Xtrain, Ytrain, Xval, Yval)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1pqW3jyWxbH"
      },
      "source": [
        "## Part (b) Checking results\n",
        "We now compare our results with the sklearn implementation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbAAypdZWxbI",
        "outputId": "70116d21-3716-4398-f9ae-24cb6eaf0588"
      },
      "source": [
        "##Import the classifier GaussianNB from sklearn.naive_bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "# Instantiate the classifier (use the parameter var_smoothing=0.0),\n",
        "# fit, and predict the classes\n",
        "##TODO##\n",
        "clf = GaussianNB(var_smoothing = 0)\n",
        "\n",
        "clf.fit(Xtrain, Ytrain)\n",
        "built_in_nb_predicts = clf.predict(Xval)\n",
        "\n",
        "built_in_nb_acc = metrics.accuracy_score(Yval, built_in_nb_predicts)\n",
        "print(\"Validation accuracy for built in:\", built_in_nb_acc)\n",
        "\n",
        "implemented_nb_acc = metrics.accuracy_score(Yval, implemented_predicts)\n",
        "print(\"Validation accuracy for manual implementation:\", implemented_nb_acc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy for built in: 0.9230769230769231\n",
            "Validation accuracy for manual implementation: 0.9230769230769231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhsNz1n0WxbI",
        "outputId": "c8cd895d-f5fa-4cc9-b709-1aa872cd8e46"
      },
      "source": [
        "# Compare your predicted classes with those of the sklearn implementation.\n",
        "# If they are not identical, this may be due to some differences in parameter setting. \n",
        "# They should be almost all the same, however.\n",
        "##TODO##\n",
        "print(built_in_nb_predicts == implemented_predicts)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cpp175kMWxbJ"
      },
      "source": [
        "## Part (c) Comparing k-nearest neighbours and Gaussian naive Bayes\n",
        "Now retrain the naive Bayes classifier using the original training set `Xtr`, `Ytr`.\n",
        "Also, retrain the k-nearest neighbours classifier using `Xtr` and `Ytr`. Use the value of $k$ that you decided on using cross-validation.\n",
        "You can use the sklearn implementations of knn and naive Bayes.\n",
        "\n",
        "Compute the accuracy of the naive Bayes classifier over the training set and the held-out test set.\n",
        "\n",
        "Compare with the accuracy of the k-nearest neighbours classifier on each set.\n",
        "\n",
        "Is it clear which classifier is the best on this dataset? why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeO9QQVBWxbJ",
        "outputId": "6f8bf142-16b9-4ce8-a84f-f69de94ae2a4"
      },
      "source": [
        "# Instantiate the knn classifer with your chosen value of k\n",
        "##TODO##\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors = 6)\n",
        "knn_classifier.fit(Xtr, Ytr)\n",
        "\n",
        "# Fit the Gaussian naive Bayes classifier and the knn classifier on Xtr, Ytr\n",
        "##TODO##\n",
        "nb_classifier = GaussianNB(var_smoothing=0)\n",
        "nb_classifier.fit(Xtr, Ytr)\n",
        "\n",
        "# Make predictions for the training set and the test set\n",
        "##TODO##\n",
        "predict_y_trn_knn = knn_classifier.predict(Xtr)\n",
        "predict_y_test_knn = knn_classifier.predict(Xtest)\n",
        "\n",
        "predict_y_trn_nb = nb_classifier.predict(Xtr)\n",
        "predict_y_test_nb = nb_classifier.predict(Xtest)\n",
        "\n",
        "# Take a look at the accuracy scores\n",
        "##TODO##\n",
        "knn_train_acc = metrics.accuracy_score(Ytr, predict_y_trn_knn)\n",
        "knn_test_acc = metrics.accuracy_score(Ytest, predict_y_test_knn)\n",
        "\n",
        "nb_train_acc = metrics.accuracy_score(Ytr, predict_y_trn_nb)\n",
        "nb_test_acc = metrics.accuracy_score(Ytest, predict_y_test_nb)\n",
        "\n",
        "print(\"KNN: Training acc:\", knn_train_acc, \" Test acc:\", knn_test_acc)\n",
        "print(\"NB: Training acc:\", nb_train_acc,\" Test acc:\", nb_test_acc)\n",
        "\n",
        "# The Naive Bayes classifier gives a better accuracy on the test set which is the\n",
        "# better accuracy to go off of. While the KNN classifier has a better accuracy on\n",
        "# the training data, it is the less valuable metric. "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN: Training acc: 0.9384615384615385  Test acc: 0.9473684210526315\n",
            "NB: Training acc: 0.9274725274725275  Test acc: 0.9649122807017544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVagFvJxWxbK"
      },
      "source": [
        "## Part (d) Using cross-validation for statistical validation\n",
        "Earlier we used cross-validation to select the model parameters we would be using. We can also use it another way: to provide statistical information about which model is best. We will set up cross-validation on the whole dataset, with 10 folds.\n",
        "\n",
        " - Compute the accuracy for each model on the test set on each fold.\n",
        " - Calculate the mean accuracy across folds. Which model performs best?\n",
        " - Make a box-plot of the spread of scores of each model. Is there a clear difference between model performance?\n",
        " - Perform a paired t-test on the accuracy scores. What can you conclude about the performance of the two models?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPBzHH3sWxbK",
        "outputId": "ed865606-dd25-469a-ebca-fb68598779f2"
      },
      "source": [
        "# Set up a k-fold cross-validation with 10 folds\n",
        "##TODO##\n",
        "kf = KFold(n_splits = 10, random_state = 56)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiA7IAzMWxbK"
      },
      "source": [
        "# For each fold, fit each model on the training data \n",
        "# and compute accuracy on the test data.\n",
        "##TODO##\n",
        "test_accs_knn = []\n",
        "test_accs_nb = []\n",
        "\n",
        "final_knn_classifier = KNeighborsClassifier(n_neighbors=6)\n",
        "final_nb_classifier = GaussianNB(var_smoothing=0)\n",
        "\n",
        "for train_idx, test_idx in kf.split(X):\n",
        "  Xtrain, Xtest = X[train_idx], X[test_idx]\n",
        "  Ytrain, Ytest = Y[train_idx], Y[test_idx]\n",
        "\n",
        "  final_knn_classifier.fit(Xtrain, Ytrain)\n",
        "  final_nb_classifier.fit(Xtrain, Ytrain)\n",
        "        \n",
        "  # make predictions \n",
        "  ##TODO##\n",
        "  knn_y_pred = final_knn_classifier.predict(Xtest)\n",
        "  nb_y_pred = final_nb_classifier.predict(Xtest)\n",
        "\n",
        "  # calculate test accuracy and store \n",
        "  ##TODO##\n",
        "  test_accs_knn.append(metrics.accuracy_score(Ytest, knn_y_pred))\n",
        "  test_accs_nb.append(metrics.accuracy_score(Ytest, nb_y_pred))\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jlg1Vfi4WxbL",
        "outputId": "0071c7d2-32a9-4ac3-84f2-1b3bd516e516"
      },
      "source": [
        "# Compute the mean and standard devation of the accuracies for each model.\n",
        "# Does one model perform better?\n",
        "##TODO##\n",
        "knn_test_acc_mean = np.mean(test_accs_knn) \n",
        "nb_test_acc_mean = np.mean(test_accs_nb)\n",
        "\n",
        "knn_test_acc_sd = np.std(test_accs_knn)\n",
        "nb_test_acc_sd = np.std(test_accs_nb)\n",
        "\n",
        "print(\"KNN average test acc:\", knn_test_acc_mean)\n",
        "print(\"NB average test acc:\", nb_test_acc_mean)\n",
        "\n",
        "print(\"KNN test acc sd:\", knn_test_acc_sd)\n",
        "print(\"NB test acc sd:\", nb_test_acc_sd)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN average test acc: 0.9244674185463658\n",
            "NB average test acc: 0.9262218045112782\n",
            "KNN test acc sd: 0.04835340341536581\n",
            "NB test acc sd: 0.03741164269199176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "rF9dtRmtWxbL",
        "outputId": "c9244a7b-90c0-4ff6-e8d4-602f0e06c51f"
      },
      "source": [
        "# Make a boxplot of the accuracy scores. (Use plt.boxplot). \n",
        "# Is there a clear difference between the models?\n",
        "##TODO##\n",
        "to_plot = [test_accs_knn, test_accs_nb]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.boxplot(to_plot)\n",
        "ax.set_xticklabels([\"KNN\", \"NB\"])\n",
        "\n",
        "# The mean accuracies of the two models are very similar but NB is generally more consistent\n",
        "# Both models have very similar upper accuracies that can be achieved but KNN had \n",
        "# The lowest value of the two."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, 'KNN'), Text(0, 0, 'NB')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6K6HeY8uWxbL",
        "outputId": "ad8c0d51-5a36-463e-c0b6-8b9989a6e03c"
      },
      "source": [
        "# Perform a paired t-test (you can use the function scipy.stats.ttest_rel). \n",
        "# What do you conclude about the performance of the two models?\n",
        "##TODO##\n",
        "from scipy import stats\n",
        "\n",
        "stats.ttest_rel(test_accs_knn, test_accs_nb)\n",
        "# assume an alpha value of 0.05\n",
        "# With a p-value of 0.919, this is incredibly far off the alpha value of 0.05\n",
        "# We can conclusively say that there is no statistically signficant difference\n",
        "# between the effectiveness of the two classifiers"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_relResult(statistic=-0.10419430674707786, pvalue=0.9193001605502058)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTzC93uAWxbL"
      },
      "source": [
        "## Linear Regression\n",
        "In linear regression we make the assumption that the data $(x_i, y_i)$ can be modelled by a function of the form\n",
        "$$ \\hat{y_i} = f(\\vec{x}_i)= \\sum_j a_j x_{ij}  + b_i$$\n",
        "\n",
        "Recall that we can express this in a matrix format by:\n",
        "$$ \\hat{\\vec{y}} = f(X)= X\\Theta$$\n",
        "\n",
        "where \n",
        "$$ X=\\begin{pmatrix}\n",
        "x_{1,1} & x_{1,2} & \\ldots & x_{1,n} &1 \\\\\n",
        "\\vdots & \\vdots & \\ldots & \\vdots & \\vdots \\\\\n",
        "x_{N,1} & x_{N,2} & \\ldots & x_{N,n} & 1\n",
        "\\end{pmatrix}, \\quad \\vec{y}=\\begin{pmatrix} y_1 \\\\ \\vdots \\\\y_N \\end{pmatrix}, \\quad \\Theta=\\begin{pmatrix} a_1 \\\\ \\vdots \\\\a_n\\\\b \\end{pmatrix}$$\n",
        "\n",
        "We saw in lectures that the optimal value of $\\Theta$ is given by setting\n",
        "$$ \\Theta = (X^T X)^{-1} X^T \\vec{y}$$\n",
        "\n",
        "The quantity $(X^T X)^{-1} X^T$ is called the psuedoinverse of X, and can be computed using the function `np.linalg.pinv`.\n",
        "\n",
        "We will (a) perform a linear regression on the diabetes dataset. You can load this dataset using the function `load_diabetes` from `sklearn.datasets`. (b) compute the mean squared error and the R^2, and (c) compare your results with the built in function in sklearn (`sklearn.linear_model.LinearRegresion()`). You should get the same results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7sXSWpSWxbM"
      },
      "source": [
        "# import statments here\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB-OsvTiWxbM"
      },
      "source": [
        "## Part (a) Implementing linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5r34x6NWxbM"
      },
      "source": [
        "# Load the diabetes dataset \n",
        "##TODO##\n",
        "diabetus_data = datasets.load_diabetes()\n",
        "X = diabetus_data.data\n",
        "Y = diabetus_data.target\n",
        "\n",
        "# Split the dataset into training and test, using test_size=0.2\n",
        "##TODO##\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Cw09M30WxbM",
        "outputId": "b5ac87a4-f7ee-4463-f2c6-66dda9764207"
      },
      "source": [
        "# Add a column of ones to Xtrain and Xtest for the intercept term\n",
        "##TODO##\n",
        "np.concatenate([Xtrain, np.ones((Xtrain.shape[0],1),dtype=Xtrain.dtype)], axis=1)\n",
        "np.concatenate([Xtest, np.ones((Xtest.shape[0],1),dtype=Xtest.dtype)], axis=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.53409833e-02, -4.46416365e-02, -6.20595414e-03,\n",
              "        -1.59992226e-02,  1.25018703e-01,  1.25198101e-01,\n",
              "         1.91869970e-02,  3.43088589e-02,  3.24332258e-02,\n",
              "        -5.21980442e-03,  1.00000000e+00],\n",
              "       [ 9.25639832e-02, -4.46416365e-02,  3.69065288e-02,\n",
              "         2.18723550e-02, -2.49601584e-02, -1.66581521e-02,\n",
              "         7.78807997e-04, -3.94933829e-02, -2.25121719e-02,\n",
              "        -2.17882321e-02,  1.00000000e+00],\n",
              "       [ 6.35036756e-02,  5.06801187e-02, -4.05032999e-03,\n",
              "        -1.25563519e-02,  1.03003457e-01,  4.87898765e-02,\n",
              "         5.60033751e-02, -2.59226200e-03,  8.44952822e-02,\n",
              "        -1.76461252e-02,  1.00000000e+00],\n",
              "       [ 9.61965216e-02, -4.46416365e-02,  5.19958979e-02,\n",
              "         7.92535333e-02,  5.48451074e-02,  3.65770865e-02,\n",
              "        -7.65355859e-02,  1.41322109e-01,  9.86463743e-02,\n",
              "         6.10539062e-02,  1.00000000e+00],\n",
              "       [ 1.26481373e-02,  5.06801187e-02, -2.02175111e-02,\n",
              "        -2.22773986e-03,  3.83336731e-02,  5.31739549e-02,\n",
              "        -6.58446761e-03,  3.43088589e-02, -5.14530798e-03,\n",
              "        -9.36191133e-03,  1.00000000e+00],\n",
              "       [ 9.01559883e-03, -4.46416365e-02, -2.45287594e-02,\n",
              "        -2.63278347e-02,  9.88755988e-02,  9.41964034e-02,\n",
              "         7.07299263e-02, -2.59226200e-03, -2.13936809e-02,\n",
              "         7.20651633e-03,  1.00000000e+00],\n",
              "       [-9.14709343e-03,  5.06801187e-02,  1.70555226e-01,\n",
              "         1.49866136e-02,  3.00779559e-02,  3.37587503e-02,\n",
              "        -2.13110188e-02,  3.43088589e-02,  3.36568129e-02,\n",
              "         3.20591578e-02,  1.00000000e+00],\n",
              "       [-2.36772472e-02,  5.06801187e-02,  4.55290254e-02,\n",
              "         2.18723550e-02,  1.09883222e-01,  8.88728796e-02,\n",
              "         7.78807997e-04,  3.43088589e-02,  7.41925367e-02,\n",
              "         6.10539062e-02,  1.00000000e+00],\n",
              "       [-9.26954778e-02,  5.06801187e-02, -9.02752959e-02,\n",
              "        -5.73136710e-02, -2.49601584e-02, -3.04366844e-02,\n",
              "        -6.58446761e-03, -2.59226200e-03,  2.40525832e-02,\n",
              "         3.06440941e-03,  1.00000000e+00],\n",
              "       [-6.00026317e-02,  5.06801187e-02,  1.53502873e-02,\n",
              "        -1.94420933e-02,  3.69577202e-02,  4.81635795e-02,\n",
              "         1.91869970e-02, -2.59226200e-03, -3.07512099e-02,\n",
              "        -1.07769750e-03,  1.00000000e+00],\n",
              "       [-4.18399395e-02, -4.46416365e-02, -3.31512560e-02,\n",
              "        -2.28849640e-02,  4.65893902e-02,  4.15874618e-02,\n",
              "         5.60033751e-02, -2.47329345e-02, -2.59524244e-02,\n",
              "        -3.83566597e-02,  1.00000000e+00],\n",
              "       [ 5.38306037e-03, -4.46416365e-02, -5.79409337e-02,\n",
              "        -2.28849640e-02, -6.76146970e-02, -6.83276482e-02,\n",
              "        -5.44457591e-02, -2.59226200e-03,  4.28956879e-02,\n",
              "        -8.39198358e-02,  1.00000000e+00],\n",
              "       [-8.90629394e-02, -4.46416365e-02, -6.11743699e-02,\n",
              "        -2.63278347e-02, -5.52311213e-02, -5.45491159e-02,\n",
              "         4.12768238e-02, -7.63945038e-02, -9.39356455e-02,\n",
              "        -5.49250874e-02,  1.00000000e+00],\n",
              "       [ 1.99132142e-02,  5.06801187e-02,  1.42724753e-02,\n",
              "         6.31868033e-02,  1.49424745e-02,  2.02933664e-02,\n",
              "        -4.70824835e-02,  3.43088589e-02,  4.66607724e-02,\n",
              "         9.00486546e-02,  1.00000000e+00],\n",
              "       [-1.27796319e-02,  5.06801187e-02, -5.57853095e-02,\n",
              "        -2.22773986e-03, -2.77120641e-02, -2.91840905e-02,\n",
              "         1.91869970e-02, -3.94933829e-02, -1.70521046e-02,\n",
              "         4.44854786e-02,  1.00000000e+00],\n",
              "       [-3.45748626e-02,  5.06801187e-02,  5.64997868e-03,\n",
              "        -5.67061055e-03, -7.31185084e-02, -6.26909759e-02,\n",
              "        -6.58446761e-03, -3.94933829e-02, -4.54209578e-02,\n",
              "         3.20591578e-02,  1.00000000e+00],\n",
              "       [ 4.17084449e-02,  5.06801187e-02,  7.13965152e-02,\n",
              "         8.10087222e-03,  3.83336731e-02,  1.59092880e-02,\n",
              "        -1.76293810e-02,  3.43088589e-02,  7.34100780e-02,\n",
              "         8.59065477e-02,  1.00000000e+00],\n",
              "       [ 6.35036756e-02,  5.06801187e-02,  8.86415084e-02,\n",
              "         7.00725447e-02,  2.04462859e-02,  3.75165318e-02,\n",
              "        -5.07641213e-02,  7.12099798e-02,  2.93004133e-02,\n",
              "         7.34802270e-02,  1.00000000e+00],\n",
              "       [-3.09423241e-02,  5.06801187e-02,  2.82840322e-02,\n",
              "         7.00725447e-02, -1.26780670e-01, -1.06844909e-01,\n",
              "        -5.44457591e-02, -4.79806407e-02, -3.07512099e-02,\n",
              "         1.54907302e-02,  1.00000000e+00],\n",
              "       [ 4.89735218e-02,  5.06801187e-02,  5.84627703e-02,\n",
              "         7.00725447e-02,  1.35665216e-02,  2.06065149e-02,\n",
              "        -2.13110188e-02,  3.43088589e-02,  2.20040505e-02,\n",
              "         2.79170509e-02,  1.00000000e+00],\n",
              "       [-7.09002471e-02, -4.46416365e-02,  3.90621530e-02,\n",
              "        -3.32135761e-02, -1.25765827e-02, -3.45076144e-02,\n",
              "        -2.49926566e-02, -2.59226200e-03,  6.77363261e-02,\n",
              "        -1.35040182e-02,  1.00000000e+00],\n",
              "       [ 4.89735218e-02, -4.46416365e-02, -4.28515646e-02,\n",
              "        -5.38708003e-02,  4.52134374e-02,  5.00424703e-02,\n",
              "         3.39135482e-02, -2.59226200e-03, -2.59524244e-02,\n",
              "        -6.32093012e-02,  1.00000000e+00],\n",
              "       [-4.18399395e-02, -4.46416365e-02, -4.93184371e-02,\n",
              "        -3.66564468e-02, -7.07277125e-03, -2.26079728e-02,\n",
              "         8.54564775e-02, -3.94933829e-02, -6.64881482e-02,\n",
              "         7.20651633e-03,  1.00000000e+00],\n",
              "       [ 5.98711371e-02,  5.06801187e-02,  2.28949719e-02,\n",
              "         4.94153205e-02,  1.63184273e-02,  1.18383580e-02,\n",
              "        -1.39477432e-02, -2.59226200e-03,  3.95398781e-02,\n",
              "         1.96328371e-02,  1.00000000e+00],\n",
              "       [-6.00026317e-02, -4.46416365e-02,  4.44512133e-02,\n",
              "        -1.94420933e-02, -9.82467697e-03, -7.57684666e-03,\n",
              "         2.28686348e-02, -3.94933829e-02, -2.71286456e-02,\n",
              "        -9.36191133e-03,  1.00000000e+00],\n",
              "       [ 4.17084449e-02,  5.06801187e-02,  1.42724753e-02,\n",
              "         4.25295792e-02, -3.04639698e-02, -1.31387743e-03,\n",
              "        -4.34008457e-02, -2.59226200e-03, -3.32487872e-02,\n",
              "         1.54907302e-02,  1.00000000e+00],\n",
              "       [ 3.08108295e-02,  5.06801187e-02,  5.95405824e-02,\n",
              "         5.63010619e-02, -2.22082527e-02,  1.19131027e-03,\n",
              "        -3.23559322e-02, -2.59226200e-03, -2.47911874e-02,\n",
              "        -1.76461252e-02,  1.00000000e+00],\n",
              "       [ 3.80759064e-02,  5.06801187e-02, -1.80618869e-02,\n",
              "         6.66296740e-02, -5.11032627e-02, -1.66581521e-02,\n",
              "        -7.65355859e-02,  3.43088589e-02, -1.19006848e-02,\n",
              "        -1.35040182e-02,  1.00000000e+00],\n",
              "       [-5.63700933e-02, -4.46416365e-02, -7.41081148e-02,\n",
              "        -5.04279296e-02, -2.49601584e-02, -4.70335528e-02,\n",
              "         9.28197531e-02, -7.63945038e-02, -6.11765951e-02,\n",
              "        -4.66408736e-02,  1.00000000e+00],\n",
              "       [ 1.62806757e-02,  5.06801187e-02, -2.12953232e-02,\n",
              "        -9.11348125e-03,  3.42058145e-02,  4.78504311e-02,\n",
              "         7.78807997e-04, -2.59226200e-03, -1.29079423e-02,\n",
              "         2.37749440e-02,  1.00000000e+00],\n",
              "       [ 2.71782911e-02, -4.46416365e-02,  9.29527567e-02,\n",
              "        -5.27231767e-02,  8.06271019e-03,  3.97085711e-02,\n",
              "        -2.86742944e-02,  2.10244554e-02, -4.83617248e-02,\n",
              "         1.96328371e-02,  1.00000000e+00],\n",
              "       [-1.03593093e-01, -4.46416365e-02, -3.74625043e-02,\n",
              "        -2.63278347e-02,  2.55889875e-03,  1.99802180e-02,\n",
              "         1.18237214e-02, -2.59226200e-03, -6.83297436e-02,\n",
              "        -2.59303390e-02,  1.00000000e+00],\n",
              "       [-1.88201653e-03,  5.06801187e-02,  1.42724753e-02,\n",
              "        -7.45280244e-02,  2.55889875e-03,  6.20168566e-03,\n",
              "        -1.39477432e-02, -2.59226200e-03,  1.91990331e-02,\n",
              "         3.06440941e-03,  1.00000000e+00],\n",
              "       [ 2.71782911e-02,  5.06801187e-02, -6.20595414e-03,\n",
              "         2.87580964e-02, -1.67044413e-02, -1.62702589e-03,\n",
              "        -5.81273969e-02,  3.43088589e-02,  2.93004133e-02,\n",
              "         3.20591578e-02,  1.00000000e+00],\n",
              "       [ 9.61965216e-02, -4.46416365e-02,  4.01399650e-02,\n",
              "        -5.73136710e-02,  4.52134374e-02,  6.06895180e-02,\n",
              "        -2.13110188e-02,  3.61539149e-02,  1.25531528e-02,\n",
              "         2.37749440e-02,  1.00000000e+00],\n",
              "       [-7.81653240e-02,  5.06801187e-02,  7.78633876e-02,\n",
              "         5.28581912e-02,  7.82363060e-02,  6.44472995e-02,\n",
              "         2.65502726e-02, -2.59226200e-03,  4.06722637e-02,\n",
              "        -9.36191133e-03,  1.00000000e+00],\n",
              "       [-9.14709343e-03,  5.06801187e-02, -3.09956318e-02,\n",
              "        -2.63278347e-02, -1.12006298e-02, -1.00072896e-03,\n",
              "        -2.13110188e-02, -2.59226200e-03,  6.20931562e-03,\n",
              "         2.79170509e-02,  1.00000000e+00],\n",
              "       [-1.88201653e-03,  5.06801187e-02, -3.31512560e-02,\n",
              "        -1.82944698e-02,  3.14539088e-02,  4.28400557e-02,\n",
              "        -1.39477432e-02,  1.99174217e-02,  1.02256424e-02,\n",
              "         2.79170509e-02,  1.00000000e+00],\n",
              "       [ 6.71362140e-02,  5.06801187e-02, -3.09956318e-02,\n",
              "         4.65800153e-03,  2.45741445e-02,  3.56376411e-02,\n",
              "        -2.86742944e-02,  3.43088589e-02,  2.33748413e-02,\n",
              "         8.17644408e-02,  1.00000000e+00],\n",
              "       [ 1.99132142e-02, -4.46416365e-02, -5.79409337e-02,\n",
              "        -5.73136710e-02, -1.56895982e-03, -1.25872221e-02,\n",
              "         7.44115641e-02, -3.94933829e-02, -6.11765951e-02,\n",
              "        -7.56356220e-02,  1.00000000e+00],\n",
              "       [-1.88201653e-03, -4.46416365e-02, -6.97968665e-02,\n",
              "        -1.25563519e-02, -1.93006962e-04, -9.14258897e-03,\n",
              "         7.07299263e-02, -3.94933829e-02, -6.29129499e-02,\n",
              "         4.03433716e-02,  1.00000000e+00],\n",
              "       [ 6.71362140e-02,  5.06801187e-02, -2.99178198e-02,\n",
              "         5.74486854e-02, -1.93006962e-04, -1.57187067e-02,\n",
              "         7.44115641e-02, -5.05637191e-02, -3.84591123e-02,\n",
              "         7.20651633e-03,  1.00000000e+00],\n",
              "       [ 4.17084449e-02,  5.06801187e-02, -2.23731352e-02,\n",
              "         2.87580964e-02, -6.62387442e-02, -4.51546621e-02,\n",
              "        -6.18090347e-02, -2.59226200e-03,  2.86377052e-03,\n",
              "        -5.49250874e-02,  1.00000000e+00],\n",
              "       [ 1.10726675e-01,  5.06801187e-02, -3.31512560e-02,\n",
              "        -2.28849640e-02, -4.32086554e-03,  2.02933664e-02,\n",
              "        -6.18090347e-02,  7.12099798e-02,  1.55668445e-02,\n",
              "         4.44854786e-02,  1.00000000e+00],\n",
              "       [ 4.17084449e-02, -4.46416365e-02, -4.50071888e-02,\n",
              "         3.44962143e-02,  4.38374845e-02, -1.57187067e-02,\n",
              "         3.75951860e-02, -1.44006207e-02,  8.98986933e-02,\n",
              "         7.20651633e-03,  1.00000000e+00],\n",
              "       [-1.64121703e-02, -4.46416365e-02, -3.53068801e-02,\n",
              "        -2.63278347e-02,  3.28298616e-02,  1.71618818e-02,\n",
              "         1.00183029e-01, -3.94933829e-02, -7.02093127e-02,\n",
              "        -7.97777289e-02,  1.00000000e+00],\n",
              "       [-9.63280163e-02, -4.46416365e-02, -3.63846922e-02,\n",
              "        -7.45280244e-02, -3.87196870e-02, -2.76183482e-02,\n",
              "         1.55053592e-02, -3.94933829e-02, -7.40888715e-02,\n",
              "        -1.07769750e-03,  1.00000000e+00],\n",
              "       [ 3.08108295e-02, -4.46416365e-02, -5.03962492e-02,\n",
              "        -2.22773986e-03, -4.42234984e-02, -8.99348921e-02,\n",
              "         1.18591218e-01, -7.63945038e-02, -1.81182673e-02,\n",
              "         3.06440941e-03,  1.00000000e+00],\n",
              "       [-2.00447088e-02, -4.46416365e-02, -8.48862355e-02,\n",
              "        -2.63278347e-02, -3.59677813e-02, -3.41944659e-02,\n",
              "         4.12768238e-02, -5.16707528e-02, -8.23814833e-02,\n",
              "        -4.66408736e-02,  1.00000000e+00],\n",
              "       [-6.00026317e-02, -4.46416365e-02,  1.33873038e-03,\n",
              "        -2.97707054e-02, -7.07277125e-03, -2.16685274e-02,\n",
              "         1.18237214e-02, -2.59226200e-03,  3.18152175e-02,\n",
              "        -5.49250874e-02,  1.00000000e+00],\n",
              "       [ 5.38306037e-03, -4.46416365e-02,  5.84627703e-02,\n",
              "        -4.35421882e-02, -7.31185084e-02, -7.23985783e-02,\n",
              "         1.91869970e-02, -7.63945038e-02, -5.14005353e-02,\n",
              "        -2.59303390e-02,  1.00000000e+00],\n",
              "       [-9.63280163e-02, -4.46416365e-02, -6.97968665e-02,\n",
              "        -6.76422830e-02, -1.94563470e-02, -1.07083313e-02,\n",
              "         1.55053592e-02, -3.94933829e-02, -4.68794828e-02,\n",
              "        -7.97777289e-02,  1.00000000e+00],\n",
              "       [ 2.71782911e-02,  5.06801187e-02,  1.75059115e-02,\n",
              "        -3.32135761e-02, -7.07277125e-03,  4.59715403e-02,\n",
              "        -6.54906725e-02,  7.12099798e-02, -9.64332229e-02,\n",
              "        -5.90671943e-02,  1.00000000e+00],\n",
              "       [ 1.99132142e-02, -4.46416365e-02, -4.06959405e-02,\n",
              "        -1.59992226e-02, -8.44872411e-03, -1.75975974e-02,\n",
              "         5.23217373e-02, -3.94933829e-02, -3.07512099e-02,\n",
              "         3.06440941e-03,  1.00000000e+00],\n",
              "       [-5.27375548e-02,  5.06801187e-02, -1.80618869e-02,\n",
              "         8.04011568e-02,  8.92439288e-02,  1.07661787e-01,\n",
              "        -3.97192078e-02,  1.08111101e-01,  3.60557901e-02,\n",
              "        -4.24987666e-02,  1.00000000e+00],\n",
              "       [-2.73097857e-02, -4.46416365e-02,  6.49296427e-02,\n",
              "        -2.22773986e-03, -2.49601584e-02, -1.72844490e-02,\n",
              "         2.28686348e-02, -3.94933829e-02, -6.11765951e-02,\n",
              "        -6.32093012e-02,  1.00000000e+00],\n",
              "       [-2.36772472e-02, -4.46416365e-02, -4.60850009e-02,\n",
              "        -3.32135761e-02,  3.28298616e-02,  3.62639380e-02,\n",
              "         3.75951860e-02, -2.59226200e-03, -3.32487872e-02,\n",
              "         1.13486232e-02,  1.00000000e+00],\n",
              "       [ 3.80759064e-02,  5.06801187e-02,  6.16962065e-02,\n",
              "         2.18723550e-02, -4.42234984e-02, -3.48207628e-02,\n",
              "        -4.34008457e-02, -2.59226200e-03,  1.99084209e-02,\n",
              "        -1.76461252e-02,  1.00000000e+00],\n",
              "       [-2.73097857e-02, -4.46416365e-02, -1.80618869e-02,\n",
              "        -4.00993175e-02, -2.94491268e-03, -1.13346282e-02,\n",
              "         3.75951860e-02, -3.94933829e-02, -8.94401896e-03,\n",
              "        -5.49250874e-02,  1.00000000e+00],\n",
              "       [-3.82074010e-02, -4.46416365e-02, -5.47074975e-02,\n",
              "        -7.79708951e-02, -3.32158756e-02, -8.64902590e-02,\n",
              "         1.40681045e-01, -7.63945038e-02, -1.91970476e-02,\n",
              "        -5.21980442e-03,  1.00000000e+00],\n",
              "       [-2.36772472e-02, -4.46416365e-02,  3.04396564e-02,\n",
              "        -5.67061055e-03,  8.23641645e-02,  9.20043642e-02,\n",
              "        -1.76293810e-02,  7.12099798e-02,  3.30470724e-02,\n",
              "         3.06440941e-03,  1.00000000e+00],\n",
              "       [-4.18399395e-02, -4.46416365e-02,  4.12177771e-02,\n",
              "        -2.63278347e-02, -3.18399227e-02, -3.04366844e-02,\n",
              "        -3.60375700e-02,  2.94290613e-03,  3.36568129e-02,\n",
              "        -1.76461252e-02,  1.00000000e+00],\n",
              "       [-6.00026317e-02,  5.06801187e-02,  5.41515220e-02,\n",
              "        -1.94420933e-02, -4.97273099e-02, -4.89124436e-02,\n",
              "         2.28686348e-02, -3.94933829e-02, -4.39854026e-02,\n",
              "        -5.21980442e-03,  1.00000000e+00],\n",
              "       [ 1.62806757e-02,  5.06801187e-02, -4.50071888e-02,\n",
              "         6.31868033e-02,  1.08146159e-02, -3.74432041e-04,\n",
              "         6.33666507e-02, -3.94933829e-02, -3.07512099e-02,\n",
              "         3.62012647e-02,  1.00000000e+00],\n",
              "       [-4.18399395e-02, -4.46416365e-02, -6.54856182e-02,\n",
              "        -4.00993175e-02, -5.69681839e-03,  1.43435457e-02,\n",
              "        -4.34008457e-02,  3.43088589e-02,  7.02686255e-03,\n",
              "        -1.35040182e-02,  1.00000000e+00],\n",
              "       [ 7.44012909e-02, -4.46416365e-02,  1.85837236e-02,\n",
              "         6.31868033e-02,  6.17248717e-02,  4.28400557e-02,\n",
              "         8.14208361e-03, -2.59226200e-03,  5.80391277e-02,\n",
              "        -5.90671943e-02,  1.00000000e+00],\n",
              "       [-5.27375548e-02,  5.06801187e-02, -1.15950145e-02,\n",
              "         5.63010619e-02,  5.62210602e-02,  7.29023080e-02,\n",
              "        -3.97192078e-02,  7.12099798e-02,  3.05664874e-02,\n",
              "        -5.21980442e-03,  1.00000000e+00],\n",
              "       [ 5.26060602e-02,  5.06801187e-02, -2.45287594e-02,\n",
              "         5.63010619e-02, -7.07277125e-03, -5.07165897e-03,\n",
              "        -2.13110188e-02, -2.59226200e-03,  2.67142576e-02,\n",
              "        -3.83566597e-02,  1.00000000e+00],\n",
              "       [-1.07225632e-01, -4.46416365e-02, -3.42290681e-02,\n",
              "        -6.76422830e-02, -6.34868384e-02, -7.05196875e-02,\n",
              "         8.14208361e-03, -3.94933829e-02, -6.09254186e-04,\n",
              "        -7.97777289e-02,  1.00000000e+00],\n",
              "       [-6.72677086e-02,  5.06801187e-02, -1.26728266e-02,\n",
              "        -4.00993175e-02, -1.53284884e-02,  4.63594335e-03,\n",
              "        -5.81273969e-02,  3.43088589e-02,  1.91990331e-02,\n",
              "        -3.42145528e-02,  1.00000000e+00],\n",
              "       [-7.45327855e-02,  5.06801187e-02, -1.80618869e-02,\n",
              "         8.10087222e-03, -1.94563470e-02, -2.48000121e-02,\n",
              "        -6.54906725e-02,  3.43088589e-02,  6.73172179e-02,\n",
              "        -1.76461252e-02,  1.00000000e+00],\n",
              "       [-1.88201653e-03,  5.06801187e-02,  3.04396564e-02,\n",
              "         5.28581912e-02,  3.97096259e-02,  5.66185880e-02,\n",
              "        -3.97192078e-02,  7.12099798e-02,  2.53931349e-02,\n",
              "         2.79170509e-02,  1.00000000e+00],\n",
              "       [ 5.98711371e-02, -4.46416365e-02, -2.12953232e-02,\n",
              "         8.72868982e-02,  4.52134374e-02,  3.15667111e-02,\n",
              "        -4.70824835e-02,  7.12099798e-02,  7.91210814e-02,\n",
              "         1.35611831e-01,  1.00000000e+00],\n",
              "       [-6.00026317e-02,  5.06801187e-02, -1.05172024e-02,\n",
              "        -1.48515991e-02, -4.97273099e-02, -2.35474182e-02,\n",
              "        -5.81273969e-02,  1.58582984e-02, -9.91895736e-03,\n",
              "        -3.42145528e-02,  1.00000000e+00],\n",
              "       [ 6.71362140e-02, -4.46416365e-02, -6.11743699e-02,\n",
              "        -4.00993175e-02, -2.63361113e-02, -2.44868636e-02,\n",
              "         3.39135482e-02, -3.94933829e-02, -5.61575731e-02,\n",
              "        -5.90671943e-02,  1.00000000e+00],\n",
              "       [ 9.01559883e-03,  5.06801187e-02, -3.96181284e-02,\n",
              "         2.87580964e-02,  3.83336731e-02,  7.35286049e-02,\n",
              "        -7.28539481e-02,  1.08111101e-01,  1.55668445e-02,\n",
              "        -4.66408736e-02,  1.00000000e+00],\n",
              "       [-2.73097857e-02,  5.06801187e-02,  6.06183944e-02,\n",
              "         4.94153205e-02,  8.51160702e-02,  8.63676919e-02,\n",
              "        -2.90282981e-03,  3.43088589e-02,  3.78144788e-02,\n",
              "         4.86275855e-02,  1.00000000e+00],\n",
              "       [-4.54724779e-02, -4.46416365e-02,  3.90621530e-02,\n",
              "         1.21513083e-03,  1.63184273e-02,  1.52829910e-02,\n",
              "        -2.86742944e-02,  2.65596235e-02,  4.45283740e-02,\n",
              "        -2.59303390e-02,  1.00000000e+00],\n",
              "       [ 4.53409833e-02,  5.06801187e-02,  1.96615356e-02,\n",
              "         3.90867085e-02,  2.04462859e-02,  2.59300387e-02,\n",
              "         8.14208361e-03, -2.59226200e-03, -3.30371258e-03,\n",
              "         1.96328371e-02,  1.00000000e+00],\n",
              "       [ 1.26481373e-02, -4.46416365e-02, -2.02175111e-02,\n",
              "        -1.59992226e-02,  1.21905688e-02,  2.12328118e-02,\n",
              "        -7.65355859e-02,  1.08111101e-01,  5.98807231e-02,\n",
              "        -2.17882321e-02,  1.00000000e+00],\n",
              "       [-8.54304009e-02, -4.46416365e-02, -4.05032999e-03,\n",
              "        -9.11348125e-03, -2.94491268e-03,  7.76742797e-03,\n",
              "         2.28686348e-02, -3.94933829e-02, -6.11765951e-02,\n",
              "        -1.35040182e-02,  1.00000000e+00],\n",
              "       [-5.63700933e-02, -4.46416365e-02, -1.15950145e-02,\n",
              "        -3.32135761e-02, -4.69754041e-02, -4.76598498e-02,\n",
              "         4.46044580e-03, -3.94933829e-02, -7.97939755e-03,\n",
              "        -8.80619427e-02,  1.00000000e+00],\n",
              "       [-4.91050164e-02, -4.46416365e-02, -6.44078061e-02,\n",
              "        -1.02070990e-01, -2.94491268e-03, -1.54055582e-02,\n",
              "         6.33666507e-02, -4.72426183e-02, -3.32487872e-02,\n",
              "        -5.49250874e-02,  1.00000000e+00],\n",
              "       [-2.73097857e-02, -4.46416365e-02, -6.00965578e-02,\n",
              "        -2.97707054e-02,  4.65893902e-02,  1.99802180e-02,\n",
              "         1.22272856e-01, -3.94933829e-02, -5.14005353e-02,\n",
              "        -9.36191133e-03,  1.00000000e+00],\n",
              "       [ 1.75052192e-03, -4.46416365e-02, -6.54856182e-02,\n",
              "        -5.67061055e-03, -7.07277125e-03, -1.94764882e-02,\n",
              "         4.12768238e-02, -3.94933829e-02, -3.30371258e-03,\n",
              "         7.20651633e-03,  1.00000000e+00],\n",
              "       [ 1.26481373e-02, -4.46416365e-02, -2.56065715e-02,\n",
              "        -4.00993175e-02, -3.04639698e-02, -4.51546621e-02,\n",
              "         7.80932019e-02, -7.63945038e-02, -7.21284546e-02,\n",
              "         1.13486232e-02,  1.00000000e+00],\n",
              "       [-2.73097857e-02, -4.46416365e-02, -6.33299941e-02,\n",
              "        -5.04279296e-02, -8.96299427e-02, -1.04339721e-01,\n",
              "         5.23217373e-02, -7.63945038e-02, -5.61575731e-02,\n",
              "        -6.73514081e-02,  1.00000000e+00],\n",
              "       [-2.36772472e-02, -4.46416365e-02, -6.97968665e-02,\n",
              "        -6.41994123e-02, -5.93589799e-02, -5.04781859e-02,\n",
              "         1.91869970e-02, -3.94933829e-02, -8.91368601e-02,\n",
              "        -5.07829805e-02,  1.00000000e+00],\n",
              "       [-6.36351702e-02, -4.46416365e-02,  3.58287167e-02,\n",
              "        -2.28849640e-02, -3.04639698e-02, -1.88501913e-02,\n",
              "        -6.58446761e-03, -2.59226200e-03, -2.59524244e-02,\n",
              "        -5.49250874e-02,  1.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZK0CZZ3WxbN",
        "outputId": "249d2b79-155d-42b2-8d3e-acf761beefe0"
      },
      "source": [
        "# Calculate the value of the coefficients theta. You can use the function np.linalg.pinv\n",
        "##TODO##\n",
        "\n",
        "def calc_variance(values, mean):\n",
        "  return sum([(x-mean)**2 for x in values])\n",
        "\n",
        "def calc_covariance(x_vals, y_vals):\n",
        "  x_vals_flat = x_vals.flatten()\n",
        "  y_vals_flat = y_vals.flatten()\n",
        "\n",
        "  mean_x = np.mean(x_vals_flat)\n",
        "  mean_y = np.mean(y_vals_flat)\n",
        "\n",
        "  n = x_vals_flat.size\n",
        "\n",
        "  return (1 / n) * np.sum((x_vals_flat - mean_x) * (y_vals_flat - mean_y))\n",
        "\n",
        "def compute_cov_matrix(y_vals, x_vals):\n",
        "  if x_vals.shape[0] != y_vals.shape[0]:\n",
        "    raise Exception(\"Shapes do not match\")\n",
        "\n",
        "  x_vals_m = np.matrix(np.mean(x_vals, axis=0).repeat(x_vals.shape[0], axis=0).reshape(x_vals.shape))\n",
        "  y_vals_m = np.matrix(np.mean(y_vals, axis=0).repeat(y_vals.shape[0], axis=0).reshape(y_vals.shape))\n",
        "\n",
        "  return ((x_vals - x_vals_m).T * (y_vals - y_vals_m)) * 1 / x_vals.shape[0]\n",
        "\n",
        "def calc_coefficients(Xvals, Yvals):\n",
        "  if Yvals.shape[1] != 1:\n",
        "    raise Exception (\"Yvals should be a vector with shape [n, 1]\")\n",
        "        \n",
        "  if Xvals.shape[0] != Yvals.shape[0]:\n",
        "    raise Exception (\"XVals should have the same amount of lines as Yvals\")\n",
        "\n",
        "  C_y_x = compute_cov_matrix(Yvals, Xvals)\n",
        "  C_x_x = compute_cov_matrix(Xvals, Xvals)\n",
        "\n",
        "  b1_bn = C_x_x.I * C_y_x\n",
        "\n",
        "  x_mean = np.matrix(np.mean(Xvals, axis=0))\n",
        "  y_mean = np.mean(Yvals)\n",
        "\n",
        "  b0 = -x_mean * b1_bn + y_mean\n",
        "\n",
        "  return (np.float(b0), np.array(b1_bn).flatten())\n",
        "\n",
        "x_m = np.matrix(Xtrain)\n",
        "y_m = np.matrix(Ytrain.reshape((Ytrain.shape[0], 1)))\n",
        "\n",
        "ret = calc_coefficients(x_m, y_m)\n",
        "\n",
        "intercept = ret[0]\n",
        "coeffs = ret[1]\n",
        "\n",
        "print(intercept)\n",
        "print(coeffs)\n",
        "\n",
        "def predict_lr(b0, bn, X):\n",
        "  return X.dot(bn) + b0"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "151.3456553477407\n",
            "[  37.90031426 -241.96624835  542.42575342  347.70830529 -931.46126093\n",
            "  518.04405547  163.40353476  275.31003837  736.18909839   48.67112488]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXfE70pYWxbN"
      },
      "source": [
        "## Part (b) Computing performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP1M6UUXWxbN"
      },
      "source": [
        "# Make a prediction on the test set by applying the coefficients theta to the test set\n",
        "##TODO##\n",
        "y_predictions_custom_lr = predict_lr(intercept, coeffs, Xtest)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqSIhZfHWxbN",
        "outputId": "14847916-4522-436a-d172-c637e89d8ff1"
      },
      "source": [
        "# Calculate the mean squared error and the R^2. \n",
        "# You can use the built in functions from sklearn\n",
        "##TODO##\n",
        "\n",
        "custom_lr_mse = metrics.mean_squared_error(Ytest, y_predictions_custom_lr)\n",
        "custom_lr_r2 = metrics.r2_score(Ytest, y_predictions_custom_lr)\n",
        "\n",
        "print(\"Custom Linear Regression MSE:\", custom_lr_mse)\n",
        "print(\"Custom Linear Regression R2:\", custom_lr_r2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Custom Linear Regression MSE: 2900.1732878832318\n",
            "Custom Linear Regression R2: 0.45260660216173787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06za6TBdWxbN"
      },
      "source": [
        "## Part (c) Checking results\n",
        "Compare your results with the built in function `sklearn.linear_model.LinearRegression()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxvUY6COWxbO"
      },
      "source": [
        "# Instantiate the linear regression\n",
        "##TODO##\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr_model = LinearRegression(fit_intercept = True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x90ZO99fWxbO",
        "outputId": "a8c19a80-e0d3-406f-c3e8-9b2abb9ad78f"
      },
      "source": [
        "# Fit the model and make a prediction on the test set. Compare with your implementation\n",
        "##TODO##\n",
        "lr_model.fit(Xtrain, Ytrain)\n",
        "\n",
        "y_preds = lr_model.predict(Xtest)\n",
        "built_in_lr_mse = metrics.mean_squared_error(Ytest, y_preds)\n",
        "built_in_lr_r2 = metrics.r2_score(Ytest, y_preds)\n",
        "\n",
        "print(\"Sklearn Linear Regression MSE:\", built_in_lr_mse)\n",
        "print(\"Sklearn Linear Regression R2:\", built_in_lr_r2)\n",
        "\n",
        "# Given the above results, the custom implementation and the sklearn implementation gave\n",
        "# The same results based on R2 and MSE, but the sklearn method is likely more optimised"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sklearn Linear Regression MSE: 2900.1732878832318\n",
            "Sklearn Linear Regression R2: 0.452606602161738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoypYFuSWxbO"
      },
      "source": [
        "Visualise the perfomance of the regression by plotting your predicted values vs target values on a scatter plot, and drawing a line y=x. If all predictions were perfect, the predicted values would lie on the line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "tl_yu8OVWxbO",
        "outputId": "f15859c2-dd08-44ea-e397-5a83bd40ba67"
      },
      "source": [
        "# Plot predicted values vs target values on a scatter plot, and drawing a line y=x\n",
        "## TODO##\n",
        "import matplotlib.lines as mlines\n",
        "import matplotlib.transforms as mtransforms\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(y_predictions_custom_lr, Ytest)\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Actual\")\n",
        "line = mlines.Line2D([0, 1], [0, 1], color='red')\n",
        "transform = ax.transAxes\n",
        "line.set_transform(transform)\n",
        "ax.add_line(line)\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy3yhBL4WxbP"
      },
      "source": [
        "# Extra question: Polynomial regression\n",
        "The term 'linear' in linear regression refers only to the coefficients $\\theta$. We can in fact compute polynomial terms in the data and perform linear regression over this extended dataset to get a better fit to the data.\n",
        "\n",
        "To compute polynomial terms in the data automatically, you can use the class `sklearn.preprocessing.PolynomialFeatures`. To find out how to use it, look at the guidance (you can type `help(PolynomialFeatures)` once you have imported it).\n",
        "\n",
        "The following small dataset (in the cell below) gives a relationship between temperature and yield for an experiment. Use cross-validation to select the degree of the polynomial that best fits this data.\n",
        "\n",
        "Plot the mean squared error against degree on the training set and on the validation set. Which degree of polynomial best fits this data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "5TtC5dzKWxbP",
        "outputId": "9cb52283-7363-491c-cec2-3787ef9f5c9e"
      },
      "source": [
        "# Data\n",
        "X = np.array([50,50,50,70,70,70,80,80,80,90,90,90,100,100,100]).reshape(-1, 1)\n",
        "y = np.array([3.3,2.8,2.9,2.3,2.6,2.1,2.5,2.9,2.4,3,3.1,2.8,3.3,3.5,3]).reshape(-1, 1)\n",
        "\n",
        "plt.plot(X, y)\n",
        "plt.show()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3GAcHLoWxbP"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox2uoQ9CWxbP",
        "outputId": "ae8857d7-c909-4240-bdfc-c59ba64bf241"
      },
      "source": [
        "max_poly = 5\r\n",
        "\r\n",
        "# Instantiate KFold with 5 splits. \r\n",
        "# Set the parameter random_state to help you reproduce your results if needed.\r\n",
        "##TODO##\r\n",
        "kf = KFold(n_splits = 5, random_state = 4)\r\n",
        "\r\n",
        "# Inititalise two variables to store the \r\n",
        "# training accuracies and validation accuracies \r\n",
        "# (these need to store max_k*5 accuracies) \r\n",
        "##TODO##\r\n",
        "train_accs = []\r\n",
        "valid_accs = []\r\n",
        "\r\n",
        "# Loop over the values of k: \r\n",
        "for p in range(max_poly):\r\n",
        "    \r\n",
        "    # Instantiate a k-nn classifier (Use the sklearn classifier)\r\n",
        "    # with the current value of k \r\n",
        "    ##TODO##\r\n",
        "    p_n_train_accs = []\r\n",
        "    p_n_valid_accs = []\r\n",
        "\r\n",
        "    # Loop over the cross-validation splits: \r\n",
        "    ##TODO##\r\n",
        "    for train_idx, test_idx in kf.split(X):\r\n",
        "        Xtrain, Xval = X[train_idx], X[test_idx]\r\n",
        "        Ytrain, Yval = Y[train_idx], Y[test_idx]\r\n",
        "        # fit the model on the current split of data \r\n",
        "        ##TODO##\r\n",
        "        poly = PolynomialFeatures(degree = p+1)\r\n",
        "        \r\n",
        "        Xtrain = poly.fit_transform(Xtrain)\r\n",
        "        Xval = poly.fit_transform(Xval)\r\n",
        "\r\n",
        "        poly = LinearRegression()\r\n",
        "        poly.fit(Xtrain, Ytrain)\r\n",
        "          \r\n",
        "        # make predictions \r\n",
        "        ##TODO##\r\n",
        "\r\n",
        "        train_y_pred = poly.predict(Xtrain)\r\n",
        "        val_y_pred = poly.predict(Xval)\r\n",
        "        \r\n",
        "        # calculate training and validation accuracy and store \r\n",
        "        ##TODO##\r\n",
        "        p_n_train_accs.append(metrics.mean_squared_error(Ytrain, train_y_pred))\r\n",
        "        p_n_valid_accs.append(metrics.mean_squared_error(Yval, val_y_pred))\r\n",
        "    \r\n",
        "    train_accs.append(np.mean(p_n_train_accs))\r\n",
        "    valid_accs.append(np.mean(p_n_valid_accs))\r\n",
        "        \r\n",
        "# Calculate the mean training and validation accuracies across splits for each 𝑘\r\n",
        "##TODO##\r\n",
        "mean_train_acc = np.mean(train_accs)\r\n",
        "mean_val_acc = np.mean(valid_accs)\r\n",
        "\r\n",
        "print(\"Training mean mse\", mean_train_acc)\r\n",
        "print(\"Validation mean mse\", mean_val_acc)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training mean mse 3403.75722999515\n",
            "Validation mean mse 93142.68258503193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "v6C6EnO1znY5",
        "outputId": "392f6b1c-2001-455c-ec04-f175abf1dc9b"
      },
      "source": [
        "p_vals = [p+1 for p in range(max_poly)]\r\n",
        "\r\n",
        "plt.plot(p_vals, train_accs, label = \"Training accuracy\")\r\n",
        "plt.plot(p_vals, valid_accs, label = \"Validation accuracy\")\r\n",
        "plt.legend(loc=\"upper right\")\r\n",
        "\r\n",
        "print(valid_accs.index(np.max(valid_accs)))\r\n",
        "# A second degree polynomial is best"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}